{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhRhd-WNMppX"
      },
      "outputs": [],
      "source": [
        "pip install httpx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37FZfDZHV8ky"
      },
      "outputs": [],
      "source": [
        "import httpx\n",
        "import asyncio\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "import sqlite3\n",
        "import os\n",
        "import nest_asyncio\n",
        "from datetime import datetime\n",
        "import torch\n",
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "GITHUB_API_URL = \"https://api.github.com/repos/SeldonIO/seldon-core/issues\"\n",
        "GITHUB_TOKEN = 'XXXXX'\n",
        "\n",
        "HEADERS = {\n",
        "    'Authorization': f'token {GITHUB_TOKEN}',\n",
        "    'User-Agent': 'score'\n",
        "}\n",
        "\n",
        "# Hugging Face Token\n",
        "\n",
        "HF_TOKEN = os.getenv('xxxxxx')\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# Load Models\n",
        "issue_type_model = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\",device=device)\n",
        "severity_model = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\",device=device)\n",
        "\n",
        "async def fetch_issues(session, state='open', per_page=100):\n",
        "    issues = []\n",
        "    page = 1\n",
        "    max_concurrent_requests = 10\n",
        "\n",
        "    async def fetch_page(page):\n",
        "        params = {'page': page, 'per_page': per_page, 'state': state}\n",
        "        try:\n",
        "            response = await session.get(GITHUB_API_URL, headers=HEADERS, params=params)\n",
        "            response.raise_for_status()\n",
        "            return response.json()\n",
        "        except httpx.RequestError as exc:\n",
        "            print(f\"An error occurred while requesting {exc.request.url!r}: {exc}\")\n",
        "            return []\n",
        "        except httpx.HTTPStatusError as exc:\n",
        "            print(f\"Error response {exc.response.status_code} while requesting {exc.request.url!r}: {exc}\")\n",
        "            return []\n",
        "\n",
        "    while True:\n",
        "        tasks = [fetch_page(page + i) for i in range(max_concurrent_requests)]\n",
        "        results = await asyncio.gather(*tasks)\n",
        "        if not any(results):\n",
        "            break\n",
        "\n",
        "        for result in results:\n",
        "            if result:\n",
        "                issues.extend(result)\n",
        "\n",
        "        page += max_concurrent_requests\n",
        "        if len(results) < max_concurrent_requests:\n",
        "            break\n",
        "\n",
        "    return issues\n",
        "\n",
        "def identify_issue_type(issue):\n",
        "    labels = [label['name'].lower() for label in issue.get('labels', [])]\n",
        "    title = (issue.get('title') or '').lower()\n",
        "\n",
        "    # Prioritize labels\n",
        "    if 'bug' in labels:\n",
        "        return 'Bug', labels\n",
        "    if 'feature request' in labels or 'enhancement' in labels:\n",
        "        return 'Feature Request', labels\n",
        "\n",
        "    # Then check titles\n",
        "    if 'bug' in title:\n",
        "        return 'Bug', labels\n",
        "    if 'feature' in title:\n",
        "        return 'Feature Request', labels\n",
        "\n",
        "    # Use the zero-shot classifier as a last resort\n",
        "    candidate_labels = [\"Bug\", \"Feature Request\", \"Other\"]\n",
        "    classification = issue_type_model(title, candidate_labels=candidate_labels)\n",
        "    return classification['labels'][0], labels\n",
        "\n",
        "def classify_severity(issue, severity_model):\n",
        "    labels = [label['name'].lower() for label in issue.get('labels', [])]\n",
        "    body = issue.get('body', '')\n",
        "\n",
        "    # Truncate the body to fit within the model's token limit (512 tokens)\n",
        "    max_length = 512  # Maximum token length for the model\n",
        "    truncated_body = body[:max_length]  # Truncate the body to the first 512 characters\n",
        "\n",
        "    # Check for severity-specific keywords first\n",
        "    if 'critical' in truncated_body.lower():\n",
        "        return 'Critical'\n",
        "\n",
        "    # Check the labels for severity\n",
        "    for label in labels:\n",
        "        if 'critical' in label:\n",
        "            return 'Critical'\n",
        "        elif 'high' in label:\n",
        "            return 'High'\n",
        "        elif 'medium' in label:\n",
        "            return 'Medium'\n",
        "        elif 'low' in label:\n",
        "            return 'Low'\n",
        "\n",
        "    # Use the zero-shot classification model if no severity label is found\n",
        "    candidate_labels = [\"Critical\", \"High\", \"Medium\", \"Low\"]\n",
        "    severity_result = severity_model(truncated_body, candidate_labels=candidate_labels)\n",
        "    severity_label = severity_result['labels'][0].lower()  # Get the top predicted label\n",
        "\n",
        "    return severity_label.capitalize()\n",
        "\n",
        "def store_issues_in_db(issues, label, db_path='issues.db'):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    c = conn.cursor()\n",
        "    c.execute('DROP TABLE IF EXISTS issues')\n",
        "    c.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS issues (\n",
        "            repo_name TEXT,\n",
        "            id INTEGER,\n",
        "            title TEXT,\n",
        "            body TEXT,\n",
        "            labels TEXT,\n",
        "            state TEXT,\n",
        "            created_at TEXT,\n",
        "            updated_at TEXT,\n",
        "            comments INTEGER,\n",
        "            user TEXT,\n",
        "            issue_type TEXT,\n",
        "            severity TEXT,\n",
        "            PRIMARY KEY (repo_name, id)\n",
        "        )\n",
        "    ''')\n",
        "\n",
        "    issue_data = []\n",
        "    for issue in issues:\n",
        "        title = (issue.get('title') or '').strip()\n",
        "        body = (issue.get('body') or '').strip()\n",
        "        if not body:  # Skip issues with empty bodies\n",
        "            continue\n",
        "\n",
        "        issue_type, labels = identify_issue_type(issue)\n",
        "        if issue_type in ['Bug', 'Feature Request']:\n",
        "            severity = classify_severity(issue, severity_model)\n",
        "            issue_data.append((\n",
        "                label,\n",
        "                issue['id'],\n",
        "                title,\n",
        "                body,\n",
        "                ','.join(labels),\n",
        "                issue['state'],\n",
        "                issue['created_at'],\n",
        "                issue['updated_at'],\n",
        "                issue['comments'],\n",
        "                issue['user']['login'],\n",
        "                issue_type,\n",
        "                severity\n",
        "            ))\n",
        "\n",
        "    c.executemany('''\n",
        "        INSERT OR IGNORE INTO issues (repo_name, id, title, body, labels, state, created_at, updated_at, comments, user, issue_type, severity)\n",
        "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "    ''', issue_data)\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "async def main():\n",
        "    async with httpx.AsyncClient() as session:\n",
        "        issues = await fetch_issues(session)\n",
        "        store_issues_in_db(issues,'score')\n",
        "\n",
        "# Run the main function\n",
        "asyncio.run(main())\n",
        "\n",
        "def print_filtered_issues(db_path='issues.db'):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT * FROM issues WHERE issue_type IN ('Bug', 'Feature Request')\")\n",
        "    rows = c.fetchall()\n",
        "\n",
        "    for row in rows:\n",
        "        print(f\"Issue ID: {row[1]}, Title: {row[2]}, Type: {row[10]}, Labels: {row[4]}\")\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "print_filtered_issues()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czsI1KJoD0ZT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_issues_from_db(db_path='issues.db'):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    df = pd.read_sql_query(\"SELECT * FROM issues WHERE issue_type IN ('Bug', 'Feature Request')\", conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "df_issues = load_issues_from_db()\n",
        "print(df_issues)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "df_issues['issue_type'].value_counts().plot(kind='bar', color=['blue', 'orange'])\n",
        "plt.title('Distribution of Issues by Type')\n",
        "plt.xlabel('Issue Type')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "severity_color_map = {\n",
        "   'Critical': '#FF0000',\n",
        "   'High': '#FF8C00',  # Dark orange\n",
        "   'Medium': '#FFD700',\n",
        "   'Low': '#008000'\n",
        "}\n",
        "\n",
        "severity_counts = df_issues['severity'].value_counts()\n",
        "\n",
        "colors = [severity_color_map[severity] for severity in severity_counts.index]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "severity_counts.plot(kind='bar', color=colors)\n",
        "plt.title('Distribution of Severity Levels')\n",
        "plt.xlabel('Severity Level')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOKZSqKO8Los"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the data from the database\n",
        "def load_issues_from_db(db_path='issues.db'):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    df = pd.read_sql_query(\"SELECT * FROM issues WHERE issue_type IN ('Bug', 'Feature Request')\", conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "df_issues = load_issues_from_db()\n",
        "\n",
        "# Ensure 'severity' column exists\n",
        "if 'severity' in df_issues.columns:\n",
        "    print(\"Severity column exists\")\n",
        "else:\n",
        "    print(\"Severity column is missing\")\n",
        "\n",
        "print(df_issues)\n",
        "\n",
        "\n",
        "\n",
        "severity_palette = {\n",
        "    'Critical': '#FF0000',\n",
        "    'High': '#FF8C00',  # Dark orange\n",
        "    'Medium': '#FFD700',\n",
        "    'Low': '#008000'\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.countplot(\n",
        "    data=df_issues,\n",
        "    x='issue_type',\n",
        "    hue='severity',\n",
        "    palette=severity_palette  # Use the custom color palette\n",
        ")\n",
        "plt.title('Distribution of Issue Types and Severities')\n",
        "plt.xlabel('Issue Type')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Severity')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcYYFUhVoLul"
      },
      "outputs": [],
      "source": [
        "df_critical_titles = df_issues[df_issues['severity'] == 'Critical']['title']\n",
        "\n",
        "print(df_critical_titles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8Ij3HuP8fib"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_issues_from_db(db_path='issues.db'):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    df = pd.read_sql_query(\"SELECT * FROM issues WHERE issue_type IN ('Bug', 'Feature Request')\", conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "df_issues = load_issues_from_db()\n",
        "\n",
        "# Convert created_at column to datetime\n",
        "df_issues['created_at'] = pd.to_datetime(df_issues['created_at'])\n",
        "\n",
        "# Add a month column\n",
        "df_issues['month'] = df_issues['created_at'].dt.to_period('M')\n",
        "\n",
        "# Group by month and issue type, then count the number of issues\n",
        "df_grouped = df_issues.groupby(['month', 'issue_type']).size().unstack().fillna(0)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(14, 7))\n",
        "df_grouped.plot(marker='o')\n",
        "plt.title('Trend of Issues Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Issues')\n",
        "plt.legend(title='Issue Type')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KnjmpjC8hk0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sqlite3\n",
        "\n",
        "# Load the issues data from the SQLite database\n",
        "def load_issues_from_db(db_path='issues.db'):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    df = pd.read_sql_query(\"SELECT * FROM issues WHERE issue_type IN ('Bug', 'Feature Request')\", conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "# Categorize and prioritize issues\n",
        "def categorize_and_prioritize_issues(df):\n",
        "    # Group by issue type and severity\n",
        "    issue_counts = df.groupby(['issue_type', 'severity']).size().unstack(fill_value=0)\n",
        "\n",
        "    # Prioritize issues by frequency\n",
        "    top_issues = df['title'].value_counts().head(10)\n",
        "\n",
        "    print(\"Issue Counts by Type and Severity:\")\n",
        "    print(issue_counts)\n",
        "\n",
        "    print(\"\\nTop 10 Frequent Issues:\")\n",
        "    print(top_issues)\n",
        "\n",
        "    # Visualize the categorization\n",
        "    issue_counts.plot(kind='bar', stacked=True)\n",
        "    plt.title('Issue Counts by Type and Severity')\n",
        "    plt.xlabel('Issue Type')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()\n",
        "\n",
        "# Temporal trends: Plot issues over time\n",
        "def plot_issues_over_time(df):\n",
        "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
        "    df.set_index('created_at').resample('M').size().plot(kind='line')\n",
        "    plt.title('Issues Over Time')\n",
        "    plt.xlabel('Month')\n",
        "    plt.ylabel('Number of Issues')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def plot_severity_distribution(df):\n",
        "    # Define the custom color palette\n",
        "    severity_color_map = {\n",
        "        'Critical': '#FF0000',\n",
        "        'High': '#FF8C00',  # Dark orange\n",
        "        'Medium': '#FFD700',\n",
        "        'Low': '#008000'\n",
        "    }\n",
        "\n",
        "    # Count the severity levels and ensure consistent ordering\n",
        "    severity_order = ['Critical', 'High', 'Medium', 'Low']\n",
        "    severity_counts = df['severity'].value_counts()\n",
        "    severity_counts = severity_counts.reindex(severity_order, fill_value=0)\n",
        "\n",
        "    # Map colors to severity levels\n",
        "    colors = [severity_color_map[severity] for severity in severity_counts.index]\n",
        "\n",
        "    # Plot the pie chart\n",
        "    severity_counts.plot(\n",
        "        kind='pie',\n",
        "        autopct='%1.1f%%',\n",
        "        startangle=140,\n",
        "        colors=colors\n",
        "    )\n",
        "    plt.title('Severity Distribution')\n",
        "    plt.ylabel('')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Analyze feature requests\n",
        "def analyze_feature_requests(df):\n",
        "    feature_requests = df[df['issue_type'] == 'Feature Request']\n",
        "    top_features = feature_requests['title'].value_counts().head(10)\n",
        "\n",
        "    print(\"Top 10 Feature Requests:\")\n",
        "    print(top_features)\n",
        "\n",
        "    # Visualize top feature requests\n",
        "    top_features.plot(kind='bar')\n",
        "    plt.title('Top 10 Feature Requests')\n",
        "    plt.xlabel('Feature Request')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()\n",
        "\n",
        "def analyze_issues(db_path='issues.db'):\n",
        "    df_issues = load_issues_from_db(db_path)\n",
        "\n",
        "    categorize_and_prioritize_issues(df_issues)\n",
        "\n",
        "    plot_issues_over_time(df_issues)\n",
        "\n",
        "    plot_severity_distribution(df_issues)\n",
        "\n",
        "    analyze_feature_requests(df_issues)\n",
        "\n",
        "# Run the analysis\n",
        "analyze_issues()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW6OhGRl9B56"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_frequency_severity_heatmap(df):\n",
        "    heatmap_data = df.pivot_table(index='issue_type', columns='severity', aggfunc='size', fill_value=0)\n",
        "    sns.heatmap(heatmap_data, annot=True, fmt='d', cmap='YlGnBu')\n",
        "    plt.title('Frequency and Severity Heatmap')\n",
        "    plt.xlabel('Severity')\n",
        "    plt.ylabel('Issue Type')\n",
        "    plt.show()\n",
        "\n",
        "plot_frequency_severity_heatmap(df_issues)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfjEnOTu9IPU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sqlite3\n",
        "from wordcloud import WordCloud\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from textblob import TextBlob\n",
        "\n",
        "\n",
        "def plot_severity_boxplot(df, metric='comments'):\n",
        "    sns.boxplot(x='severity', y=metric, data=df)\n",
        "    plt.title(f'{metric.capitalize()} by Severity')\n",
        "    plt.xlabel('Severity')\n",
        "    plt.ylabel(metric.capitalize())\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Sentiment Analysis\n",
        "def perform_sentiment_analysis(df):\n",
        "    df['sentiment'] = df['body'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "    sns.boxplot(x='issue_type', y='sentiment', data=df)\n",
        "    plt.title('Sentiment Analysis of Issues')\n",
        "    plt.xlabel('Issue Type')\n",
        "    plt.ylabel('Sentiment Polarity')\n",
        "    plt.show()\n",
        "\n",
        "def analyze_issues(db_path='issues.db'):\n",
        "\n",
        "    plot_severity_boxplot(df_issues, metric='comments')\n",
        "\n",
        "\n",
        "    perform_sentiment_analysis(df_issues)\n",
        "\n",
        "analyze_issues()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TM943aj-GuH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "def fetch_and_print_issues(db_path='issues.db'):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    c = conn.cursor()\n",
        "\n",
        "    c.execute(\"SELECT issue_type, title, severity FROM issues WHERE issue_type IN ('Bug', 'Feature Request')\")\n",
        "    rows = c.fetchall()\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=['type', 'detail', 'severity'])\n",
        "\n",
        "    print(df)\n",
        "    print(f\"Number of rows: {len(df)}\")\n",
        "\n",
        "fetch_and_print_issues()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHXw-_Yt-bRS"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "custom_stopwords = set(stopwords.words('english')).union({\n",
        "    'adding', 'protects', 'code', 'implementation', 'check', 'endpoint', 'key', 'function'\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "def load_issues_from_db(db_path='issues.db'):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    df = pd.read_sql_query(\"SELECT * FROM issues WHERE issue_type IN ('Bug', 'Feature Request')\", conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    words = text.split()\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "def preprocess_issues(df):\n",
        "    df['processed_body'] = df['body'].apply(preprocess_text)\n",
        "    return df\n",
        "\n",
        "df_issues = load_issues_from_db()\n",
        "df_issues = preprocess_issues(df_issues)\n",
        "\n",
        "print(df_issues[['body', 'processed_body']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FUl2kmq-mvt"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def extract_keywords(df, n_keywords=10):\n",
        "    vectorizer = TfidfVectorizer(max_features=n_keywords)\n",
        "    X = vectorizer.fit_transform(df['processed_body'])\n",
        "\n",
        "    keywords = vectorizer.get_feature_names_out()\n",
        "    tfidf_scores = X.toarray()\n",
        "\n",
        "    for i, keyword in enumerate(keywords):\n",
        "        df[keyword] = tfidf_scores[:, i]\n",
        "\n",
        "    return df, keywords\n",
        "\n",
        "df_issues, keywords = extract_keywords(df_issues)\n",
        "\n",
        "print(df_issues.head())\n",
        "print(\"Extracted Keywords:\", keywords)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xxuRZVZ-rMN"
      },
      "outputs": [],
      "source": [
        "categories = {\n",
        "    'Bug Report': [\n",
        "        'bug', 'error', 'failure', 'issue', 'crash', 'exception', 'fault',\n",
        "        'defect', 'glitch', 'malfunction', 'problem', 'breakdown', 'hang',\n",
        "        'freeze', 'stop', 'wrong', 'unexpected', 'terminate', 'shutdown', 'abort',\n",
        "        'buggy', 'unresponsive', 'deadlock', 'incorrect'\n",
        "    ],\n",
        "    'Performance Issue': [\n",
        "        'performance', 'slow', 'latency', 'lag', 'delay', 'inefficient',\n",
        "        'sluggish', 'unresponsive', 'hang', 'freeze', 'optimization', 'speed',\n",
        "        'throughput', 'memory leak', 'resource', 'bottleneck', 'load', 'scalability',\n",
        "        'high CPU', 'high memory', 'overhead', 'resource utilization'\n",
        "    ],\n",
        "    'Compatibility Problem': [\n",
        "        'compatibility', 'support', 'platform', 'integration', 'incompatible',\n",
        "        'conflict', 'portability', 'version', 'dependency', 'interop', 'environment',\n",
        "        'OS', 'system', 'architecture', 'framework', 'library', 'API', 'browser',\n",
        "        'device', 'hardware', 'software', 'backward', 'forward', 'compliance',\n",
        "        'adaptation', 'adoption', 'standard', 'specification'\n",
        "    ],\n",
        "    'Enhancement Request': [\n",
        "        'enhancement', 'feature', 'request', 'improve', 'add', 'upgrade',\n",
        "        'update', 'expand', 'extend', 'new functionality', 'suggestion', 'proposal',\n",
        "        'better', 'enhance', 'more', 'increase', 'boost', 'develop', 'modify',\n",
        "        'refine', 'revamp', 'strengthen', 'superior', 'augmented', 'additional',\n",
        "        'extra', 'integrate', 'customize', 'personalize', 'streamline', 'innovate'\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "def categorize_issue(body):\n",
        "    body = body.lower()\n",
        "    for category, keywords in categories.items():\n",
        "        if any(keyword in body for keyword in keywords):\n",
        "            return category\n",
        "    return 'Other'\n",
        "\n",
        "df_issues['category'] = df_issues['processed_body'].apply(categorize_issue)\n",
        "\n",
        "print(df_issues[['body', 'processed_body', 'category']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5t8AiQkf-vMh"
      },
      "outputs": [],
      "source": [
        "def save_processed_issues_to_db(df, db_path='issues.db'):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    df.to_sql('issues', conn, if_exists='replace', index=False)\n",
        "    conn.close()\n",
        "\n",
        "def preprocess_and_save_issues(db_path='issues.db'):\n",
        "    df_issues = load_issues_from_db(db_path)\n",
        "\n",
        "    df_issues = preprocess_issues(df_issues)\n",
        "\n",
        "    df_issues['category'] = df_issues['processed_body'].apply(categorize_issue)\n",
        "\n",
        "    save_processed_issues_to_db(df_issues, db_path)\n",
        "\n",
        "preprocess_and_save_issues()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Em_Fk0OK-zrx"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def extract_top_keywords(df, category, n_keywords=10):\n",
        "    category_issues = df[df['category'] == category]\n",
        "    vectorizer = TfidfVectorizer(max_features=n_keywords)\n",
        "    X = vectorizer.fit_transform(category_issues['processed_body'])\n",
        "\n",
        "    tfidf_scores = X.toarray().sum(axis=0)\n",
        "    keywords = vectorizer.get_feature_names_out()\n",
        "\n",
        "    keyword_scores = dict(zip(keywords, tfidf_scores))\n",
        "    sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return sorted_keywords\n",
        "\n",
        "def plot_top_keywords(keywords, title):\n",
        "    keywords, scores = zip(*keywords)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(keywords, scores, color='skyblue')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('TF-IDF Score')\n",
        "    plt.ylabel('Keywords')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.show()\n",
        "\n",
        "def analyze_trending_issues(df):\n",
        "    feature_keywords = extract_top_keywords(df, 'Enhancement Request')\n",
        "    bug_keywords = extract_top_keywords(df, 'Bug Report')\n",
        "\n",
        "    print(\"Top Keywords in Feature Requests:\")\n",
        "    print(feature_keywords)\n",
        "\n",
        "    print(\"Top Keywords in Bug Reports:\")\n",
        "    print(bug_keywords)\n",
        "\n",
        "    plot_top_keywords(feature_keywords, 'Top Keywords in Feature Requests')\n",
        "    plot_top_keywords(bug_keywords, 'Top Keywords in Bug Reports')\n",
        "\n",
        "def analyze_issues(db_path='issues.db'):\n",
        "    df_issues = load_issues_from_db(db_path)\n",
        "\n",
        "    plot_severity_distribution(df_issues)\n",
        "\n",
        "    critical_issues = df_issues[df_issues['severity'].str.lower() == 'critical']\n",
        "\n",
        "    analyze_trending_issues(df_issues)\n",
        "\n",
        "analyze_issues()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMf3CbmKBlTD"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def extract_keywords_and_phrases(df, category, n_keywords=10):\n",
        "    category_issues = df[df['category'] == category]\n",
        "    vectorizer = TfidfVectorizer(max_features=n_keywords, stop_words='english')\n",
        "    X = vectorizer.fit_transform(category_issues['processed_body'])\n",
        "\n",
        "    tfidf_scores = X.toarray().sum(axis=0)\n",
        "    keywords = vectorizer.get_feature_names_out()\n",
        "\n",
        "    keyword_scores = dict(zip(keywords, tfidf_scores))\n",
        "    sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    keyword_phrases = defaultdict(list)\n",
        "\n",
        "    for keyword, _ in sorted_keywords:\n",
        "        for body in category_issues['processed_body']:\n",
        "            if keyword in body:\n",
        "                phrases = re.findall(r'([^.]*?\\b' + re.escape(keyword) + r'\\b[^.]*\\.)', body)\n",
        "                keyword_phrases[keyword].extend(phrases)\n",
        "\n",
        "    return sorted_keywords, keyword_phrases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2M16ZkcYXew"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def extract_top_phrases_with_titles(df, category, n_phrases=10):\n",
        "    category_issues = df[df['category'] == category]\n",
        "\n",
        "    vectorizer = TfidfVectorizer(max_features=n_phrases, stop_words='english', ngram_range=(3, 3))\n",
        "    X = vectorizer.fit_transform(category_issues['processed_body'])\n",
        "\n",
        "    tfidf_scores = X.toarray().sum(axis=0)\n",
        "    phrases = vectorizer.get_feature_names_out()\n",
        "\n",
        "    phrase_scores = dict(zip(phrases, tfidf_scores))\n",
        "    sorted_phrases = sorted(phrase_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    phrase_titles = defaultdict(list)\n",
        "\n",
        "    for phrase, _ in sorted_phrases:\n",
        "        for body, title in zip(category_issues['processed_body'], category_issues['title']):\n",
        "            if phrase in body:\n",
        "                phrase_titles[phrase].append(title)\n",
        "\n",
        "    return sorted_phrases, phrase_titles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VrbMRltCCdx"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "def visualize_phrases_with_titles(phrases, phrase_titles, title):\n",
        "    phrases, scores = zip(*phrases)\n",
        "    titles = [\"<br>\".join(phrase_titles[phrase][:3]) for phrase in phrases]  # Limiting to top 3 titles for clarity\n",
        "\n",
        "    df = pd.DataFrame({'Phrase': phrases, 'Score': scores, 'Titles': titles})\n",
        "\n",
        "    fig = px.bar(df, x='Score', y='Phrase', orientation='h',\n",
        "                 hover_data={'Titles': True},\n",
        "                 labels={'Score': 'TF-IDF Score', 'Phrase': 'Phrases'},\n",
        "                 title=title)\n",
        "\n",
        "    fig.update_layout(\n",
        "        yaxis=dict(tickmode='linear'),\n",
        "        hovermode=\"closest\",\n",
        "        height=600,\n",
        "        margin=dict(l=200, r=20, t=60, b=20)\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "def analyze_phrases_and_titles(df, category, title):\n",
        "    top_phrases, phrase_titles = extract_top_phrases_with_titles(df, category)\n",
        "    visualize_phrases_with_titles(top_phrases, phrase_titles, title)\n",
        "\n",
        "def load_issues_from_db(db_path='issues.db'):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    df = pd.read_sql_query(\"SELECT * FROM issues WHERE issue_type IN ('Bug', 'Feature Request')\", conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "def analyze_issues(db_path='issues.db'):\n",
        "    df_issues = load_issues_from_db(db_path)\n",
        "\n",
        "    analyze_phrases_and_titles(df_issues, 'Enhancement Request', 'Top Phrases and Titles in Feature Requests')\n",
        "    analyze_phrases_and_titles(df_issues, 'Bug Report', 'Top Phrases and Titles in Bug Reports')\n",
        "\n",
        "analyze_issues()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhYR1nKrvnVB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "\n",
        "def get_top_phrases_and_titles(df_issues, top_n=10):\n",
        "    critical_issues = df_issues[df_issues['severity'] == 'Critical']\n",
        "\n",
        "    bodies = critical_issues['body'].tolist()\n",
        "\n",
        "    vectorizer = TfidfVectorizer(ngram_range=(2, 3), stop_words='english')  # Bigrams and Trigrams\n",
        "    tfidf_matrix = vectorizer.fit_transform(bodies)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    phrase_scores = tfidf_matrix.sum(axis=0).A1\n",
        "    phrase_scores_dict = dict(zip(feature_names, phrase_scores))\n",
        "\n",
        "    top_phrases = Counter(phrase_scores_dict).most_common(top_n)\n",
        "\n",
        "    top_phrases_data = []\n",
        "\n",
        "    for phrase, score in top_phrases:\n",
        "        for _, row in critical_issues.iterrows():\n",
        "            if phrase in row['body']:\n",
        "                top_phrases_data.append({\n",
        "                    'Phrase': phrase,\n",
        "                    'Issue Title': row['title']\n",
        "                })\n",
        "\n",
        "    top_phrases_df = pd.DataFrame(top_phrases_data)\n",
        "\n",
        "    return top_phrases_df\n",
        "\n",
        "top_phrases_df = get_top_phrases_and_titles(df_issues)\n",
        "\n",
        "print(top_phrases_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpgO5BSABmbK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List of key phrases\n",
        "key_phrases = [\n",
        "    \"LLM\", \"Large Language Model\", \"Language Model\", \"Transformer Model\", \"GPT\", \"BERT\",\n",
        "    \"OpenAI\", \"Hugging Face\", \"Model Training\", \"Model Inference\", \"Prompt Engineering\",\n",
        "    \"Model Fine-tuning\", \"Inference Latency\", \"Model Deployment\", \"Tokenization Issues\",\n",
        "    \"Attention Mechanism\", \"Model Scaling\", \"Context Length\", \"Model Performance\",\n",
        "    \"Natural Language Processing\", \"Pretrained Model\", \"Model Weights\", \"Parameter Tuning\",\n",
        "    \"Model Outputs\", \"Bias in Models\", \"Model Interpretability\",\n",
        "    \"Issues with LLM deployment\", \"Model inference time too high\",\n",
        "    \"Error during model fine-tuning\", \"Unexpected output from GPT model\",\n",
        "    \"LLM tokenization error\", \"Memory issue with large models\"\n",
        "]\n",
        "\n",
        "def filter_issues_by_phrases(df_issues, key_phrases):\n",
        "    filtered_issues = df_issues[\n",
        "        df_issues['title'].apply(lambda x: any(phrase.lower() in x.lower() for phrase in key_phrases)) |\n",
        "        df_issues['body'].apply(lambda x: any(phrase.lower() in x.lower() for phrase in key_phrases))\n",
        "    ]\n",
        "    return filtered_issues\n",
        "\n",
        "filtered_df = filter_issues_by_phrases(df_issues, key_phrases)\n",
        "\n",
        "print(filtered_df[['title', 'body']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fh631qJ66QC_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "key_phrases = [\n",
        "    \"LLM\", \"Large Language Model\", \"Language Model\", \"Transformer Model\", \"GPT\", \"BERT\",\n",
        "    \"OpenAI\", \"Hugging Face\", \"Model Training\", \"Model Inference\", \"Prompt Engineering\",\n",
        "    \"Model Fine-tuning\", \"Inference Latency\", \"Model Deployment\", \"Tokenization Issues\",\n",
        "    \"Attention Mechanism\", \"Model Scaling\", \"Context Length\", \"Model Performance\",\n",
        "    \"Natural Language Processing\", \"Pretrained Model\", \"Model Weights\", \"Parameter Tuning\",\n",
        "    \"Model Outputs\", \"Bias in Models\", \"Model Interpretability\",\n",
        "    \"Issues with LLM deployment\", \"Model inference time too high\",\n",
        "    \"Error during model fine-tuning\", \"Unexpected output from GPT model\",\n",
        "    \"LLM tokenization error\", \"Memory issue with large models\"\n",
        "]\n",
        "\n",
        "def filter_issues_by_phrases_and_severity(df_issues, key_phrases):\n",
        "    filtered_issues = df_issues[\n",
        "        ((df_issues['severity'] == 'High') | (df_issues['severity'] == 'Critical')) &\n",
        "        (df_issues['title'].apply(lambda x: any(phrase.lower() in x.lower() for phrase in key_phrases)) |\n",
        "         df_issues['body'].apply(lambda x: any(phrase.lower() in x.lower() for phrase in key_phrases)))\n",
        "    ]\n",
        "    return filtered_issues\n",
        "\n",
        "filtered_df = filter_issues_by_phrases_and_severity(df_issues, key_phrases)\n",
        "\n",
        "print(filtered_df[['title', 'severity', 'body']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpSHiVql-T7e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List of key phrases\n",
        "key_phrases = [\n",
        "  \"High GPU usage\", \"Computational overhead\", \"Hardware limitations\", \"GPU/TPU requirement\",\n",
        "    \"Data preprocessing\", \"Data quality issues\", \"Training data imbalance\", \"Data bias\",\n",
        "    \"Scalability challenges\", \"Infrastructure scaling\", \"Inference latency\", \"Resource optimization\",\n",
        "    \"Model fine-tuning\", \"Prompt engineering\", \"Quantization\", \"Model compression\",\n",
        "    \"High operational cost\", \"Cost of inference\", \"API throttling\", \"Energy consumption\",\n",
        "    \"Bias in LLMs\", \"Ethical AI deployment\", \"Fairness in AI\", \"Model transparency\",\n",
        "    \"Security vulnerabilities\", \"Adversarial attacks\", \"Data privacy\", \"Model security\",\n",
        "    \"Black box model\", \"Interpretability challenges\", \"Explainability\", \"Model transparency\",\n",
        "    \"Compliance with GDPR\", \"AI regulations\", \"Data protection laws\", \"Legal risks\",\n",
        "    \"Inference accuracy\", \"Model hallucination\", \"Response consistency\", \"Performance degradation\"\n",
        "]\n",
        "\n",
        "def filter_issues_by_phrases_and_severity(df_issues, key_phrases):\n",
        "    filtered_issues = df_issues[\n",
        "        ((df_issues['severity'] == 'High') | (df_issues['severity'] == 'Critical') | (df_issues['severity'] == 'Medium')) &\n",
        "        (df_issues['title'].apply(lambda x: any(phrase.lower() in x.lower() for phrase in key_phrases)) |\n",
        "         df_issues['body'].apply(lambda x: any(phrase.lower() in x.lower() for phrase in key_phrases)))\n",
        "    ]\n",
        "    return filtered_issues\n",
        "\n",
        "filtered_df = filter_issues_by_phrases_and_severity(df_issues, key_phrases)\n",
        "\n",
        "print(filtered_df[['title', 'severity', 'body']])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWakhPHK5piM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List of key phrases\n",
        "key_phrases = [\n",
        "    \"LLM\", \"Large Language Model\", \"Language Model\", \"Transformer Model\", \"GPT\", \"BERT\",\n",
        "    \"OpenAI\", \"Hugging Face\", \"Model Training\", \"Model Inference\", \"Prompt Engineering\",\n",
        "    \"Model Fine-tuning\", \"Inference Latency\", \"Model Deployment\", \"Tokenization Issues\",\n",
        "    \"Attention Mechanism\", \"Model Scaling\", \"Context Length\", \"Model Performance\",\n",
        "    \"Natural Language Processing\", \"Pretrained Model\", \"Model Weights\", \"Parameter Tuning\",\n",
        "    \"Model Outputs\", \"Bias in Models\", \"Model Interpretability\",\n",
        "    \"Issues with LLM deployment\", \"Model inference time too high\",\n",
        "    \"Error during model fine-tuning\", \"Unexpected output from GPT model\",\n",
        "    \"LLM tokenization error\", \"Memory issue with large models\"\n",
        "]\n",
        "\n",
        "def filter_issues_by_phrases_and_severity(df_issues, key_phrases):\n",
        "    filtered_issues = df_issues[\n",
        "        ((df_issues['severity'] == 'High') | (df_issues['severity'] == 'Critical')) &\n",
        "        (df_issues['title'].apply(lambda x: any(phrase.lower() in x.lower() for phrase in key_phrases)) |\n",
        "         df_issues['body'].apply(lambda x: any(phrase.lower() in x.lower() for phrase in key_phrases)))\n",
        "    ]\n",
        "    return filtered_issues\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "filtered_df = filter_issues_by_phrases_and_severity(df_issues, key_phrases)\n",
        "\n",
        "print(filtered_df[['title', 'severity', 'body']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMP-3khPQcCQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "key_phrases = [\n",
        "    \"reducing hallucinations\",\n",
        "    \"Adversarial attacks\",\n",
        "    \"mitigating hallucinations in LLMs\",\n",
        "    \"reward functions to penalize hallucinations\",\n",
        "    \"context-aware generation\",\n",
        "    \"chain-of-thought prompting\",\n",
        "    \"optimizing context length\",\n",
        "    \"retrieval-augmented generation (RAG)\",\n",
        "    \"prompt engineering\",\n",
        "    \"efficiency in context processing\",\n",
        "    \"multimodal LLMs\",\n",
        "    \"text and image integration\",\n",
        "    \"multimodal data in LLMs\",\n",
        "    \"cost reduction in LLMs\",\n",
        "    \"efficient LLMs\",\n",
        "    \"LLM memory optimization\",\n",
        "    \"faster LLM models\",\n",
        "    \"alternative LLM architectures\",\n",
        "    \"transformer alternatives\",\n",
        "    \"scalable LLM architectures\",\n",
        "    \"self-attention in transformers\",\n",
        "    \"improving transformer efficiency\",\n",
        "    \"LLM hallucination detection\",\n",
        "    \"context learning in LLMs\",\n",
        "    \"scaling LLMs efficiently\",\n",
        "    \"improving LLM reliability\",\n",
        "    \"long-context LLM processing\",\n",
        "    \"modality fusion in AI\",\n",
        "    \"multimodal embeddings\",\n",
        "    \"LLM interpretability\",\n",
        "    \"distributed LLM training\",\n",
        "    \"flash attention\",\n",
        "    \"watermarking in LLMs\",\n",
        "    \"LLM bias mitigation\"\n",
        "]\n",
        "\n",
        "\n",
        "def filter_issues_by_phrases_and_severity(df_issues, key_phrases):\n",
        "    filtered_issues = df_issues[\n",
        "        ((df_issues['severity'] == 'High') | (df_issues['severity'] == 'Critical')) &\n",
        "        (df_issues['title'].apply(lambda x: any(phrase.lower() in x.lower() for phrase in key_phrases)) |\n",
        "         df_issues['body'].apply(lambda x: any(phrase.lower() in x.lower() for phrase in key_phrases)))\n",
        "    ]\n",
        "    return filtered_issues\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "filtered_df = filter_issues_by_phrases_and_severity(df_issues, key_phrases)\n",
        "\n",
        "print(filtered_df[['title', 'severity', 'body']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIbr0VLNr-pU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "key_phrases = [\n",
        "    \"reducing hallucinations\",\n",
        "    \"mitigating hallucinations in LLMs\",\n",
        "    \"reward functions to penalize hallucinations\",\n",
        "    \"context-aware generation\",\n",
        "    \"chain-of-thought prompting\",\n",
        "    \"optimizing context length\",\n",
        "    \"retrieval-augmented generation (RAG)\",\n",
        "    \"prompt engineering\",\n",
        "    \"efficiency in context processing\",\n",
        "    \"multimodal LLMs\",\n",
        "    \"text and image integration\",\n",
        "    \"multimodal data in LLMs\",\n",
        "    \"cost reduction in LLMs\",\n",
        "    \"efficient LLMs\",\n",
        "    \"LLM memory optimization\",\n",
        "    \"faster LLM models\",\n",
        "    \"alternative LLM architectures\",\n",
        "    \"transformer alternatives\",\n",
        "    \"scalable LLM architectures\",\n",
        "    \"self-attention in transformers\",\n",
        "    \"improving transformer efficiency\",\n",
        "    \"LLM hallucination detection\",\n",
        "    \"context learning in LLMs\",\n",
        "    \"scaling LLMs efficiently\",\n",
        "    \"improving LLM reliability\",\n",
        "    \"long-context LLM processing\",\n",
        "    \"modality fusion in AI\",\n",
        "    \"multimodal embeddings\",\n",
        "    \"LLM interpretability\",\n",
        "    \"distributed LLM training\",\n",
        "    \"flash attention\",\n",
        "    \"watermarking in LLMs\",\n",
        "    \"LLM bias mitigation\"\n",
        "]\n",
        "\n",
        "\n",
        "def filter_issues_by_phrases_and_severity(df_issues, key_phrases):\n",
        "    filtered_issues = df_issues[\n",
        "        ((df_issues['severity'] == 'High') | (df_issues['severity'] == 'Critical')) &\n",
        "        (df_issues['title'].apply(lambda x: any(phrase.lower() in x.lower() for phrase in key_phrases)) |\n",
        "         df_issues['body'].apply(lambda x: any(phrase.lower() in x.lower() for phrase in key_phrases)))\n",
        "    ]\n",
        "    return filtered_issues\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "filtered_df = filter_issues_by_phrases_and_severity(df_issues, key_phrases)\n",
        "\n",
        "print(filtered_df[['title', 'severity', 'body']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyofuVnxs4Wj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "key_phrases = [\n",
        "  \"prompt caching\",\n",
        "  \"LLM prompt optimization\",\n",
        "  \"prompt reuse\",\n",
        "  \"cached prompts\",\n",
        "  \"inference caching\",\n",
        "  \"query caching\",\n",
        "  \"LLM response caching\",\n",
        "  \"prompt result caching\",\n",
        "  \"prompt-response pairs\",\n",
        "  \"cached embeddings\",\n",
        "  \"model prompt cache\",\n",
        "  \"token cache\",\n",
        "  \"memory-efficient prompt handling\",\n",
        "  \"cached LLM output\",\n",
        "  \"zero-shot prompt caching\",\n",
        "  \"prompt retrieval optimization\",\n",
        "  \"preprocessed prompt cache\",\n",
        "  \"inference optimization\",\n",
        "  \"prompt persistence\",\n",
        "  \"request-response caching\"\n",
        "]\n",
        "\n",
        "# Function to filter issues by key phrases and severity\n",
        "def filter_issues_by_phrases_and_severity(df_issues, key_phrases):\n",
        "    filtered_issues = df_issues[\n",
        "        ((df_issues['severity'] == 'High') | (df_issues['severity'] == 'Critical')) &\n",
        "        (df_issues['title'].apply(lambda x: any(phrase.lower() in x.lower() for phrase in key_phrases)) |\n",
        "         df_issues['body'].apply(lambda x: any(phrase.lower() in x.lower() for phrase in key_phrases)))\n",
        "    ]\n",
        "    return filtered_issues\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "filtered_df = filter_issues_by_phrases_and_severity(df_issues, key_phrases)\n",
        "\n",
        "print(filtered_df[['title', 'severity', 'body']])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}